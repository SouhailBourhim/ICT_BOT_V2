"""
G√©n√©rateur d'embeddings avec support multilingue (fran√ßais)
"""
from typing import List, Union
import numpy as np
from sentence_transformers import SentenceTransformer
from loguru import logger
import torch


class EmbeddingGenerator:
    """
    G√©n√©rateur d'embeddings vectoriels pour textes
    Utilise SentenceTransformers avec support du fran√ßais
    """
    
    # Mod√®les recommand√©s pour le fran√ßais
    FRENCH_MODELS = {
        'multilingual_mini': 'paraphrase-multilingual-MiniLM-L12-v2',  # Rapide, 384 dim
        'multilingual_mpnet': 'paraphrase-multilingual-mpnet-base-v2',  # Meilleur qualit√©, 768 dim
        'camembert': 'dangvantuan/sentence-camembert-large',  # Sp√©cifique fran√ßais
    }
    
    def __init__(
        self,
        model_name: str = 'paraphrase-multilingual-MiniLM-L12-v2',
        device: str = None,
        batch_size: int = 32
    ):
        """
        Initialise le g√©n√©rateur d'embeddings
        
        Args:
            model_name: Nom du mod√®le SentenceTransformer
            device: 'cuda', 'cpu' ou None (auto-d√©tection)
            batch_size: Taille des batchs pour l'encodage
        """
        self.model_name = model_name
        self.batch_size = batch_size
        
        # D√©tection automatique du device
        if device is None:
            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'
        else:
            self.device = device
        
        logger.info(f"Chargement du mod√®le: {model_name} sur {self.device}")
        
        try:
            self.model = SentenceTransformer(model_name, device=self.device)
            self.embedding_dimension = self.model.get_sentence_embedding_dimension()
            
            logger.success(f"‚úÖ Mod√®le charg√©: {self.embedding_dimension} dimensions")
            
        except Exception as e:
            logger.error(f"Erreur lors du chargement du mod√®le: {e}")
            raise
    
    def generate_embedding(self, text: str) -> np.ndarray:
        """
        G√©n√®re un embedding pour un texte unique
        
        Args:
            text: Texte √† encoder
            
        Returns:
            Vecteur numpy de dimensions [embedding_dimension]
        """
        if not text or not text.strip():
            logger.warning("Texte vide, retour d'un vecteur nul")
            return np.zeros(self.embedding_dimension)
        
        try:
            embedding = self.model.encode(
                text,
                convert_to_numpy=True,
                show_progress_bar=False,
                normalize_embeddings=True  # Normalisation L2 pour similarit√© cosinus
            )
            
            return embedding
            
        except Exception as e:
            logger.error(f"Erreur lors de la g√©n√©ration d'embedding: {e}")
            raise
    
    def generate_embeddings_batch(
        self, 
        texts: List[str],
        show_progress: bool = True
    ) -> np.ndarray:
        """
        G√©n√®re des embeddings pour plusieurs textes (plus efficace)
        
        Args:
            texts: Liste de textes √† encoder
            show_progress: Afficher la barre de progression
            
        Returns:
            Matrice numpy de dimensions [len(texts), embedding_dimension]
        """
        if not texts:
            logger.warning("Liste de textes vide")
            return np.array([])
        
        # Filtrer les textes vides
        valid_texts = [t if t and t.strip() else " " for t in texts]
        
        logger.info(f"G√©n√©ration de {len(valid_texts)} embeddings (batch_size={self.batch_size})")
        
        try:
            embeddings = self.model.encode(
                valid_texts,
                batch_size=self.batch_size,
                convert_to_numpy=True,
                show_progress_bar=show_progress,
                normalize_embeddings=True
            )
            
            logger.success(f"‚úÖ {len(embeddings)} embeddings g√©n√©r√©s")
            
            return embeddings
            
        except Exception as e:
            logger.error(f"Erreur lors de la g√©n√©ration batch: {e}")
            raise
    
    def compute_similarity(
        self, 
        embedding1: np.ndarray, 
        embedding2: np.ndarray
    ) -> float:
        """
        Calcule la similarit√© cosinus entre deux embeddings
        
        Args:
            embedding1: Premier vecteur
            embedding2: Second vecteur
            
        Returns:
            Score de similarit√© [0, 1]
        """
        # Produit scalaire (les embeddings sont d√©j√† normalis√©s)
        similarity = np.dot(embedding1, embedding2)
        
        return float(similarity)
    
    def compute_similarity_matrix(
        self, 
        embeddings1: np.ndarray, 
        embeddings2: np.ndarray
    ) -> np.ndarray:
        """
        Calcule la matrice de similarit√© entre deux ensembles d'embeddings
        
        Args:
            embeddings1: Matrice [N, dim]
            embeddings2: Matrice [M, dim]
            
        Returns:
            Matrice de similarit√© [N, M]
        """
        # Produit matriciel pour toutes les paires
        similarity_matrix = np.dot(embeddings1, embeddings2.T)
        
        return similarity_matrix
    
    def find_most_similar(
        self, 
        query_embedding: np.ndarray, 
        corpus_embeddings: np.ndarray,
        top_k: int = 5
    ) -> List[tuple]:
        """
        Trouve les K embeddings les plus similaires dans un corpus
        
        Args:
            query_embedding: Embedding de la requ√™te [dim]
            corpus_embeddings: Embeddings du corpus [N, dim]
            top_k: Nombre de r√©sultats √† retourner
            
        Returns:
            Liste de tuples (index, score) tri√©s par similarit√© d√©croissante
        """
        # Calcul des similarit√©s
        similarities = np.dot(corpus_embeddings, query_embedding)
        
        # Top K indices
        top_indices = np.argsort(similarities)[::-1][:top_k]
        
        # R√©sultats avec scores
        results = [(int(idx), float(similarities[idx])) for idx in top_indices]
        
        return results
    
    def save_embeddings(self, embeddings: np.ndarray, filepath: str):
        """Sauvegarde des embeddings sur disque"""
        try:
            np.save(filepath, embeddings)
            logger.info(f"Embeddings sauvegard√©s: {filepath}")
        except Exception as e:
            logger.error(f"Erreur lors de la sauvegarde: {e}")
            raise
    
    def load_embeddings(self, filepath: str) -> np.ndarray:
        """Charge des embeddings depuis le disque"""
        try:
            embeddings = np.load(filepath)
            logger.info(f"Embeddings charg√©s: {embeddings.shape}")
            return embeddings
        except Exception as e:
            logger.error(f"Erreur lors du chargement: {e}")
            raise
    
    def get_model_info(self) -> dict:
        """Retourne les informations sur le mod√®le"""
        return {
            'model_name': self.model_name,
            'embedding_dimension': self.embedding_dimension,
            'device': self.device,
            'batch_size': self.batch_size,
            'max_seq_length': self.model.max_seq_length
        }


# Test du g√©n√©rateur
if __name__ == "__main__":
    # Initialisation
    embedder = EmbeddingGenerator()
    
    # Textes de test en fran√ßais
    texts = [
        "L'Internet des Objets transforme notre quotidien.",
        "Les capteurs IoT collectent des donn√©es en temps r√©el.",
        "La cybers√©curit√© est essentielle pour prot√©ger les syst√®mes.",
        "Le machine learning permet d'analyser les donn√©es IoT."
    ]
    
    # G√©n√©ration d'embeddings
    print("\nüìä G√©n√©ration d'embeddings...")
    embeddings = embedder.generate_embeddings_batch(texts)
    print(f"Shape: {embeddings.shape}")
    
    # Test de similarit√©
    query = "Comment s√©curiser un r√©seau IoT ?"
    query_emb = embedder.generate_embedding(query)
    
    print(f"\nüîç Requ√™te: {query}")
    results = embedder.find_most_similar(query_emb, embeddings, top_k=3)
    
    print("\nR√©sultats les plus similaires:")
    for idx, score in results:
        print(f"  [{score:.3f}] {texts[idx]}")
    
    # Informations mod√®le
    print(f"\nüìã Info mod√®le: {embedder.get_model_info()}")